# ğŸ¤– Physical AI & Humanoid Robotics

> A comprehensive educational resource covering the fundamentals of Physical AI, sensors, simulation, control strategies, and real-world robotics implementation.

[![Built with Docusaurus](https://img.shields.io/badge/Built%20with-Docusaurus-success)](https://docusaurus.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](CONTRIBUTING.md)

## ğŸ“š About This Book

This interactive educational book provides a complete learning path from foundational concepts to advanced implementations in Physical AI and humanoid robotics. Perfect for students, researchers, and robotics enthusiasts.

### ğŸ¯ What You'll Learn

- **Embodied Intelligence**: Understanding the sense-think-act loop
- **Sensors & Actuators**: Hardware fundamentals and integration
- **Simulation**: Digital twins, PyBullet, Gazebo, Isaac Sim
- **Control Strategies**: Reactive, deliberative, hybrid, and learned control
- **Capstone Projects**: Hands-on implementation from beginner to expert

## ğŸ“– Book Structure

### Chapter 1: Embodied Intelligence
Introduction to Physical AI concepts, the sense-think-act loop, and real-world applications.

### Chapter 2: Sensors & Actuators
Comprehensive coverage of sensor types (cameras, LIDAR, IMU), actuators (motors, servos), and sensor fusion techniques.

### Chapter 3: Simulation
Digital twins, simulation platforms comparison, setup guides, and sim-to-real transfer strategies.

### Chapter 4: Control Strategies
From PID controllers to reinforcement learning - reactive control, path planning, behavior trees, and more.

### Chapter 5: Capstone Project
Complete project guide with 8+ project ideas, requirements, evaluation rubrics, and detailed examples.

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18.0 or higher
- npm or yarn

### Installation

```bash
# Clone the repository
git clone https://github.com/YOUR-USERNAME/physical-ai-robotics-book.git
cd physical-ai-robotics-book

# Install dependencies
npm install

# Start development server
npm start
```

Open [http://localhost:3000](http://localhost:3000) to view the book.

### Build for Production

```bash
npm run build
npm run serve
```

## ğŸ¤– RAG Chatbot Setup

The book includes an AI-powered chatbot that can answer questions about the content using Retrieval-Augmented Generation (RAG).

### Quick Setup (15 minutes)

See **[QUICK-START-CHATBOT.md](QUICK-START-CHATBOT.md)** for a 15-minute setup guide.

### Full Setup Guide

See **[CHATBOT-SETUP-GUIDE.md](CHATBOT-SETUP-GUIDE.md)** for comprehensive deployment instructions.

### Features

- ğŸ’¬ Ask questions about any chapter
- âœ‚ï¸ Select text and get instant explanations
- ğŸ“š Automatic source citations
- ğŸ’¾ Conversation history saved to database
- ğŸ¯ Chapter-aware context filtering
- ğŸ” User authentication integration

### Test the Chatbot

```bash
# Start backend
cd backend
python rag_chatbot.py

# In another terminal, embed content
cd backend
python embed_all_content.py

# In another terminal, start frontend
npm start
```

Open http://localhost:3000 and click the chatbot icon (bottom right)!

## ğŸ“Š Content Statistics

- **ğŸ“„ Pages**: 29 comprehensive chapters
- **ğŸ“ Words**: 56,000+ words of content
- **ğŸ’» Code Examples**: 100+ working examples
- **ğŸ Languages**: Python and C++
- **ğŸ¯ Exercises**: Multiple per chapter
- **ğŸ† Projects**: 8 capstone project ideas

## ğŸ› ï¸ Technologies Used

### Frontend
- **Framework**: [Docusaurus](https://docusaurus.io/)
- **Language**: TypeScript, React
- **Deployment**: Vercel
- **Authentication**: Better Auth (Google/GitHub OAuth)

### Backend (RAG Chatbot)
- **API**: FastAPI (Python)
- **AI**: OpenAI GPT-4o-mini, text-embedding-3-small
- **Vector DB**: Qdrant Cloud (Free Tier)
- **Database**: Neon Serverless Postgres
- **Deployment**: Render.com / Docker

## ğŸ“ Learning Path

```
Week 1-2  â†’ Chapter 1: Embodied Intelligence
Week 3-4  â†’ Chapter 2: Sensors & Actuators
Week 5-6  â†’ Chapter 3: Simulation
Week 7-9  â†’ Chapter 4: Control Strategies
Week 10+  â†’ Chapter 5: Capstone Project
```

## ğŸ’¡ Features

- âœ… **Interactive Code Examples** with syntax highlighting
- âœ… **Multi-language Support** (Python/C++ tabs)
- âœ… **Responsive Design** for mobile and desktop
- âœ… **Dark Mode** support
- âœ… **Search Functionality**
- âœ… **Progressive Learning** from basics to advanced
- âœ… **Hands-on Exercises** with solutions
- âœ… **Real-world Projects** with detailed guidance
- âœ… **ğŸ¤– AI-Powered RAG Chatbot** - Ask questions about book content
- âœ… **Selected Text Queries** - Highlight text and ask for explanations
- âœ… **User Authentication** - Google/GitHub OAuth integration
- âœ… **Content Personalization** - Tailored learning experiences

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### How to Contribute

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸŒŸ Acknowledgments

- Built with [Docusaurus](https://docusaurus.io/)
- Inspired by the Physical AI and robotics community
- Code examples tested with PyBullet, ROS, and MuJoCo

## ğŸ“§ Contact

**Author**: Your Name  
**Email**: your.email@example.com  
**GitHub**: [@yourusername](https://github.com/yourusername)

## ğŸ”— Links

- **Live Demo**: [https://your-site.vercel.app](https://your-site.vercel.app)
- **Documentation**: [https://your-site.vercel.app/docs/intro](https://your-site.vercel.app/docs/intro)
- **Issues**: [GitHub Issues](https://github.com/YOUR-USERNAME/physical-ai-robotics-book/issues)

## â­ Star History

If you find this resource helpful, please consider giving it a star! â­

---

**Made with â¤ï¸ for the robotics community**
